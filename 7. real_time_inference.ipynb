{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f6464a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%writefile` not found.\n"
     ]
    }
   ],
   "source": [
    "# Publish pipeline\n",
    "\n",
    "%%writefile training_pipeline/scoring.py\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def init():\n",
    "    global model, scaler\n",
    "    model_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"wine-quality-lr/1/model.pkl\")\n",
    "    print(model_path)\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    scaler_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"wine-quality-scaler/15/scaler.pkl\")\n",
    "    with open(scaler_path, \"rb\") as f:\n",
    "        scaler = pickle.load(f)\n",
    "    \n",
    "    \n",
    "def run(raw_data):\n",
    "    data = np.array(json.loads(raw_data)[\"data\"])\n",
    "    prepped = scaler.transform(data)\n",
    "    predictions = model.predict(prepped)\n",
    "    return predictions.tolist()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb61bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.environment import CondaDependencies\n",
    "service_env = Environment(name=\"service-env\")\n",
    "service_env.python.conda_dependencies = CondaDependencies.create(python_version=\"3.8\",\n",
    "                                                                            pip_packages=[\"numpy\", \"pandas\",\n",
    "                                                                                          \"scikit-learn\", \"azureml-core\",\n",
    "                                                                                          \"azureml-defaults\", \"azureml-pipeline\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57359c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-01-27 14:28:39+00:00 Registering the environment.\n",
      "2022-01-27 14:28:43+00:00 Use the existing image.\n",
      "2022-01-27 14:28:43+00:00 Generating deployment configuration.\n",
      "2022-01-27 14:28:45+00:00 Submitting deployment to compute..\n",
      "2022-01-27 14:28:52+00:00 Checking the status of deployment wine-quality-aci..\n",
      "2022-01-27 14:30:34+00:00 Checking the status of inference endpoint wine-quality-aci.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2022-01-27T14:30:20,689212300+00:00 - iot-server/run \\n2022-01-27T14:30:20,690709100+00:00 - rsyslog/run \\n2022-01-27T14:30:20,702757200+00:00 - gunicorn/run \\nDynamic Python package installation is disabled.\\nStarting HTTP server\\n2022-01-27T14:30:20,809522200+00:00 - nginx/run \\nStarting gunicorn 20.1.0\\nListening at: http://127.0.0.1:31311 (73)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 95\\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2022-01-27T14:30:21,736970900+00:00 - iot-server/finish 1 0\\n2022-01-27T14:30:21,743957700+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nSPARK_HOME not set. Skipping PySpark Initialization.\\nInitializing logger\\n2022-01-27 14:30:22,331 | root | INFO | Starting up app insights client\\nlogging socket was found. logging is available.\\nlogging socket was found. logging is available.\\n2022-01-27 14:30:22,332 | root | INFO | Starting up request id generator\\n2022-01-27 14:30:22,333 | root | INFO | Starting up app insight hooks\\n2022-01-27 14:30:22,333 | root | INFO | Invoking user\\'s init function\\n/var/azureml-app/azureml-models/wine-quality-lr/1/model.pkl\\nno request id,/var/azureml-app/azureml-models/wine-quality-lr/1/model.pkl\\n\\n2022-01-27 14:30:23,273 | root | INFO | Users\\'s init has completed successfully\\n2022-01-27 14:30:23,280 | root | INFO | Skipping middleware: dbg_model_info as it\\'s not enabled.\\n2022-01-27 14:30:23,280 | root | INFO | Skipping middleware: dbg_resource_usage as it\\'s not enabled.\\n2022-01-27 14:30:23,283 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\\n2022-01-27 14:30:34,657 | root | INFO | Swagger file not present\\n2022-01-27 14:30:34,657 | root | INFO | 404\\n127.0.0.1 - - [27/Jan/2022:14:30:34 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\\n2022-01-27 14:30:40,178 | root | INFO | Swagger file not present\\n2022-01-27 14:30:40,178 | root | INFO | 404\\n127.0.0.1 - - [27/Jan/2022:14:30:40 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core import Workspace\n",
    "\n",
    "model_inference_config = InferenceConfig(source_directory=\"training_pipeline\",\n",
    "                                        entry_script=\"scoring.py\",\n",
    "                                        environment=service_env)\n",
    "\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "model2 = Model(ws, name=\"wine-quality-lr\")\n",
    "model1 = Model(ws, name=\"wine-quality-scaler\")\n",
    "service = Model.deploy(ws, \"wine-quality-aci\", [model1, model2], model_inference_config, aci_config)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)\n",
    "\n",
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "123fda07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[0, 0, 0, 0, 0]'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "data = {\"data\": [[6.6, 0.45, 0.43, 7.2, 0.064, 31.0, 186.0, 0.9954, 3.12, 0.44, 9.4],\n",
    " [8.1, 0.3, 0.49, 12.3, 0.049, 50.0, 144.0, 0.9971, 3.09, 0.57, 10.2],\n",
    " [5.9, 0.27, 0.27, 9.0, 0.051, 43.0, 136.0, 0.9941, 3.25, 0.53, 10.7],\n",
    " [6.5, 0.28, 0.35, 9.8, 0.067, 61.0, 180.0, 0.9972, 3.15, 0.57, 9.0],\n",
    " [6.4, 0.27, 0.49, 7.3, 0.046, 53.0, 206.0, 0.9956, 3.24, 0.43, 9.2]]\n",
    "\n",
    "}\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "url = 'http://a2a7dde7-a1c6-414a-ad27-350cc3ab3559.centralindia.azurecontainer.io/score'\n",
    "api_key = '' # Replace this with the API key for the web service\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea71b077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.run(input_data=json.dumps({\"data\": [[6.6, 0.45, 0.43, 7.2, 0.064, 31.0, 186.0, 0.9954, 3.12, 0.44, 9.4],\n",
    " [8.1, 0.3, 0.49, 12.3, 0.049, 50.0, 144.0, 0.9971, 3.09, 0.57, 10.2],\n",
    " [5.9, 0.27, 0.27, 9.0, 0.051, 43.0, 136.0, 0.9941, 3.25, 0.53, 10.7],\n",
    " [6.5, 0.28, 0.35, 9.8, 0.067, 61.0, 180.0, 0.9972, 3.15, 0.57, 9.0],\n",
    " [6.4, 0.27, 0.49, 7.3, 0.046, 53.0, 206.0, 0.9956, 3.24, 0.43, 9.2]]\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39378e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
